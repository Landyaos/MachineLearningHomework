{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集载入\n",
    "TRAIN_PATH='./data/MovieReview/train.txt'\n",
    "TEST_PATH='./data/MovieReview/test.txt'\n",
    "VAL_PATH='./data/MovieReview/validation.txt'\n",
    "def load_data(path):\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        data = []\n",
    "        lable = []\n",
    "        for line in f.readlines():\n",
    "            if line == '\\n':\n",
    "                continue\n",
    "            data.append(line[2:].split())\n",
    "            lable.append(int(line[0]))\n",
    "        return data, lable\n",
    "train_data, train_lable = load_data(TRAIN_PATH)\n",
    "test_data, test_lable = load_data(TEST_PATH)\n",
    "val_data, val_lable = load_data(VAL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集pading\n",
    "SEQUENCE_LEN = 50 \n",
    "def data_padding(sequence):\n",
    "    if len(sequence) >= SEQUENCE_LEN:\n",
    "        sequence = sequence[:SEQUENCE_LEN]\n",
    "    else:\n",
    "        pad_len = SEQUENCE_LEN - len(sequence)\n",
    "        for _ in range(pad_len):\n",
    "            sequence.append(\"<PAD>\")\n",
    "    assert len(sequence) == SEQUENCE_LEN\n",
    "    return sequence\n",
    "train_data = [data_padding(seq) for seq in train_data]\n",
    "test_data = [data_padding(seq) for seq in test_data]\n",
    "val_data = [data_padding(seq) for seq in val_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集映射\n",
    "word2idx = {'<PAD>': 0, '<UNK>': 1, '<SOS>': 2, '<EOS>': 3}\n",
    "idx2word = {0: '<PAD>', 1: '<UNK>', 2: '<SOS>', 3: '<EOS>'}\n",
    "for data in [train_data, test_data, val_data]:\n",
    "    for review in data:\n",
    "        for word in review:\n",
    "            if word not in word2idx.keys():\n",
    "                word2idx[word] = len(word2idx)\n",
    "                idx2word[len(word2idx)] = word\n",
    "train_data = [[word2idx[word] for word in review] for review in train_data]\n",
    "test_data = [[word2idx[word] for word in review] for review in test_data]\n",
    "val_data = [[word2idx[word] for word in review] for review in val_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集embedding\n",
    "W2V_FILE='./data/MovieReview/wiki_word2vec_50.bin'\n",
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format(W2V_FILE, binary=True)\n",
    "idx2vec = np.array(np.random.uniform(-1., 1., [len(word2idx), model.vector_size]))\n",
    "for word in word2idx.keys():\n",
    "   if model.has_index_for(word):\n",
    "        idx2vec[word2idx[word]] = model[word] \n",
    "idx2vec = torch.from_numpy(idx2vec).requires_grad_(True).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieReviewDataset(Dataset):\n",
    "    def __init__(self, data, lable):\n",
    "        self.data = torch.tensor(data, dtype=torch.long)\n",
    "        self.label = torch.tensor(lable, dtype=torch.long)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.label[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.attention_weights = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention_scores = self.attention_weights(x)\n",
    "        attention_weights = self.softmax(attention_scores)\n",
    "        attended_representation = torch.bmm(attention_weights.unsqueeze(1), x)\n",
    "        return attended_representation.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieReviewSentimentClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim, pretrained_embeded_weight) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_layer = nn.Embedding(pretrained_embeded_weight.shape[0], pretrained_embeded_weight.shape[1])\n",
    "        self.embedding_layer.weight.data.copy_(pretrained_embeded_weight)\n",
    "        self.lstm_layer = nn.LSTM(pretrained_embeded_weight.shape[1], hidden_dim, num_layers=1, batch_first=True)\n",
    "        # self.attention = SelfAttention(hidden_dim * 2)\n",
    "        self.linear_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024,512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512,2)\n",
    "        ) \n",
    "\n",
    "    def forward(self, input):\n",
    "        batch_size, seq_len = input.shape\n",
    "        embedded = self.embedding_layer(input)\n",
    "        h_0 = torch.zeros(1, batch_size, self.hidden_dim, device=input.device, dtype=torch.float, requires_grad=True)\n",
    "        c_0 = torch.zeros(1, batch_size, self.hidden_dim, device=input.device, dtype=torch.float, requires_grad=True)\n",
    "        output, hidden = self.lstm_layer(embedded, (h_0,c_0))\n",
    "        # output = self.attention(output)\n",
    "        output = self.linear_layer(output[:,-1,:])\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=56\n",
    "HIDDEN_DIM=256\n",
    "LR=1e-3\n",
    "EPOCHS=10\n",
    "PATH = './MovieReviewSentimentClassificationModel.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, criterion, dataloader):\n",
    "    model.eval()\n",
    "    print(\">>>>>> Model Test Begin......\")\n",
    "    correct = 0\n",
    "    batch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_lable in dataloader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_lable = batch_lable.to(device)\n",
    "            output, _ = model(batch_data)\n",
    "            loss = criterion(output, batch_lable)\n",
    "            batch_loss += loss\n",
    "            correct += (output.argmax(1) ==\n",
    "                        batch_lable).type(torch.float).sum().item()\n",
    "    correct /= len(dataloader.dataset)\n",
    "    print(\n",
    "        f\"Test Error: \\n Accuracy:{(100*correct):>0.1f} % , Avg loss : {batch_loss/len(dataloader):>8f} \\n\")\n",
    "    print(\">>>>>> Model Train End.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, dataloader):\n",
    "    model.train()\n",
    "    print(\">>>>>> Model Train Begin......\")\n",
    "    for epoch_idx in range(EPOCHS):\n",
    "        epoch_loss = 0\n",
    "        print(f\"Epoch {epoch_idx}\\n-------------------------------\")\n",
    "        for batch_idx, (batch_data, batch_lable) in enumerate(dataloader):\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_lable = batch_lable.to(device)\n",
    "            output, _ = model(batch_data)\n",
    "            loss = criterion(output, batch_lable)\n",
    "            epoch_loss += loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (batch_idx+1) % 100 == 0:\n",
    "                print(\n",
    "                    f'[{(batch_idx+1) * len(batch_data)}/{len(dataloader.dataset)} \\\n",
    "                      ({100. * batch_idx / len(dataloader):.0f}%)]\\t \\\n",
    "                      loss: {loss.item():.6f}')\n",
    "        print(f'Epoch {epoch_idx}\\tAVG loss= {epoch_loss/len(dataloader):.6f}\\n')\n",
    "        \n",
    "    print(\">>>>>> Model Train End.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MovieReviewDataset(train_data, train_lable)\n",
    "test_dataset = MovieReviewDataset(test_data, test_lable)\n",
    "val_dataset = MovieReviewDataset(val_data, val_lable)\n",
    "train_dataloader = DataLoader(train_dataset,BATCH_SIZE,True)\n",
    "test_dataloader = DataLoader(test_dataset,BATCH_SIZE,True)\n",
    "val_dataloader = DataLoader(val_dataset,BATCH_SIZE,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>> Model Train Begin......\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[5600/19998                       (28%)]\t                       loss: 0.468949\n",
      "[11200/19998                       (56%)]\t                       loss: 0.484156\n",
      "[16800/19998                       (84%)]\t                       loss: 0.327856\n",
      "Epoch 0\tAVG loss= 0.548735\n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[5600/19998                       (28%)]\t                       loss: 0.312568\n",
      "[11200/19998                       (56%)]\t                       loss: 0.346361\n",
      "[16800/19998                       (84%)]\t                       loss: 0.512075\n",
      "Epoch 1\tAVG loss= 0.381541\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[5600/19998                       (28%)]\t                       loss: 0.195073\n",
      "[11200/19998                       (56%)]\t                       loss: 0.285429\n",
      "[16800/19998                       (84%)]\t                       loss: 0.309189\n",
      "Epoch 2\tAVG loss= 0.274350\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[5600/19998                       (28%)]\t                       loss: 0.141223\n",
      "[11200/19998                       (56%)]\t                       loss: 0.384938\n",
      "[16800/19998                       (84%)]\t                       loss: 0.117499\n",
      "Epoch 3\tAVG loss= 0.188365\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[5600/19998                       (28%)]\t                       loss: 0.022645\n",
      "[11200/19998                       (56%)]\t                       loss: 0.348057\n",
      "[16800/19998                       (84%)]\t                       loss: 0.170230\n",
      "Epoch 4\tAVG loss= 0.122965\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[5600/19998                       (28%)]\t                       loss: 0.066352\n",
      "[11200/19998                       (56%)]\t                       loss: 0.047200\n",
      "[16800/19998                       (84%)]\t                       loss: 0.160240\n",
      "Epoch 5\tAVG loss= 0.091146\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[5600/19998                       (28%)]\t                       loss: 0.005939\n",
      "[11200/19998                       (56%)]\t                       loss: 0.023620\n",
      "[16800/19998                       (84%)]\t                       loss: 0.085463\n",
      "Epoch 6\tAVG loss= 0.063203\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[5600/19998                       (28%)]\t                       loss: 0.034140\n",
      "[11200/19998                       (56%)]\t                       loss: 0.054681\n",
      "[16800/19998                       (84%)]\t                       loss: 0.086985\n",
      "Epoch 7\tAVG loss= 0.045649\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[5600/19998                       (28%)]\t                       loss: 0.003008\n",
      "[11200/19998                       (56%)]\t                       loss: 0.133212\n",
      "[16800/19998                       (84%)]\t                       loss: 0.116521\n",
      "Epoch 8\tAVG loss= 0.031100\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[5600/19998                       (28%)]\t                       loss: 0.007662\n",
      "[11200/19998                       (56%)]\t                       loss: 0.002585\n",
      "[16800/19998                       (84%)]\t                       loss: 0.001798\n",
      "Epoch 9\tAVG loss= 0.023448\n",
      "\n",
      ">>>>>> Model Train End.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MovieReviewSentimentClassificationModel(HIDDEN_DIM,idx2vec).to(device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train(model, optimizer, criterion, train_dataloader)\n",
    "# torch.save(model.state_dict(), PATH)\n",
    "model.load_state_dict(torch.load(PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>> Model Test Begin......\n",
      "Test Error: \n",
      " Accuracy:83.2 % , Avg loss : 0.696980 \n",
      "\n",
      ">>>>>> Model Train End.\n"
     ]
    }
   ],
   "source": [
    "test(model, criterion, test_dataloader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
